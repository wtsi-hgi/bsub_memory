{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dn10/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dn10/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written so far: 319.74 MB\n",
      "Written so far: 573.07 MB\n",
      "Written so far: 772.61 MB\n",
      "Written so far: 911.79 MB\n",
      "Written so far: 1070.62 MB\n",
      "Written so far: 1425.34 MB\n",
      "Written so far: 1822.23 MB\n",
      "Written so far: 2215.33 MB\n",
      "Written so far: 2578.79 MB\n",
      "Written so far: 2912.58 MB\n",
      "Written so far: 3231.09 MB\n",
      "Written so far: 3483.26 MB\n",
      "Written so far: 3629.16 MB\n",
      "Written so far: 3750.34 MB\n",
      "Written so far: 3784.89 MB\n",
      "Written so far: 4043.36 MB\n",
      "Written so far: 4348.55 MB\n",
      "Written so far: 4673.26 MB\n",
      "Written so far: 4811.32 MB\n",
      "Written so far: 4970.51 MB\n",
      "Written so far: 5093.94 MB\n",
      "Written so far: 5171.45 MB\n",
      "File size limit reached. Stopping.\n"
     ]
    }
   ],
   "source": [
    "#from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import os\n",
    "\n",
    "# Path to input and output\n",
    "input_path = \"/Users/dn10/Downloads/Bsub_dataset/data.jsonl.gz\"\n",
    "output_path = \"/Users/dn10/Downloads/Bsub_dataset/filtered_under_1GB.jsonl\"\n",
    "\n",
    "# Target size limit (in bytes) - 5GB\n",
    "size_limit = 5 * 1024 * 1024 * 1024  # 5 GB\n",
    "\n",
    "# Open output file for writing\n",
    "with open(output_path, \"w\") as output_file:\n",
    "    for chunk in pd.read_json(input_path, \n",
    "                              lines=True, \n",
    "                              compression='gzip', \n",
    "                              chunksize=100000):\n",
    "\n",
    "        # Filter rows that contain #BSUB in 'Command' column\n",
    "        filtered_chunk = chunk[chunk['Command'].str.contains('#BSUB', case=False, na=False)]\n",
    "\n",
    "        # Write to file in JSONL format\n",
    "        filtered_chunk.to_json(output_file, orient='records', lines=True)\n",
    "\n",
    "        # Check file size after writing\n",
    "        current_size = os.path.getsize(output_path)\n",
    "        print(f\"Written so far: {round(current_size / (1024 ** 2), 2)} MB\")\n",
    "\n",
    "        if current_size >= size_limit:\n",
    "            print(\"File size limit reached. Stopping.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(output_path, lines=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a histogram\n",
    "plt.hist(df[\"MAX_MEM_USAGE_MB\"], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(x=df['MAX_MEM_USAGE_MB'])\n",
    "plt.xscale('log')  # Optional: helps if values vary a lot\n",
    "plt.title(\"Boxplot of Memory Usage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MAX_MEM_USAGE_MB'].quantile([0.25, 0.5, 0.75, 0.90, 0.95, 0.99, 0.999])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, column= \"MAX_MEM_USAGE_MB\", min_mem_mb = 1.0, quantile = 0.99, bins =100, samples_per_bin=1000, random_state=42):\n",
    "    \"\"\"\n",
    "    Preprocess the data by filtering and binning.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        column (str): Column name to filter on.\n",
    "        min_mem_mb (float): Minimum memory usage in MB.\n",
    "        quantile (float): Quantile to filter on.\n",
    "        bins (int): Number of bins for histogram.\n",
    "        samples_per_bin (int): Number of samples per bin.\n",
    "        random_state (int): Random state for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "    # Filter jobs with low memory\n",
    "    df = df[df[column] >= min_mem_mb].copy()\n",
    "    \n",
    "    # Calculate the upper bound using quantile\n",
    "    upper_bound = df[column].quantile(quantile)\n",
    "    \n",
    "    # Further filter rows based on the upper bound\n",
    "    df = df[df[column] <= upper_bound].reset_index(drop=True)\n",
    "    \n",
    "    # Bin the data\n",
    "    #df['bin'] = pd.qcut(df[column], q=bins, duplicates='drop')\n",
    "    df['bin'] = pd.cut(df[column], bins=bins, duplicates='drop')\n",
    "    \n",
    "    # Sample from each bin\n",
    "    sampled_df = df.groupby('bin').apply(lambda x: x.sample(min(len(x), samples_per_bin), random_state=random_state))\n",
    "    \n",
    "    # drop the bin column\n",
    "    sampled_df = sampled_df.reset_index(drop=True)\n",
    "    sampled_df = sampled_df.drop(columns=['bin'])\n",
    "    # Reset index\n",
    "    sampled_df = sampled_df.reset_index(drop=True)\n",
    "    \n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = preprocess_data(df, column=\"MAX_MEM_USAGE_MB\", min_mem_mb=1.0, quantile=0.99, bins=100, samples_per_bin=1000, random_state=42)\n",
    "print(f\"Number of rows after preprocessing: {len(df_balanced)}\")\n",
    "df_balanced.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['MAX_MEM_USAGE_MB'].hist(bins=50, edgecolor='black')\n",
    "#groupby;sampling;reformatting.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-TinyBERT-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-TinyBERT-L6-v2')\n",
    "encoded_input = tokenizer(df['Command'][0], padding=True, truncation=True, return_tensors='pt')\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
    "print(encoded_input[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each command in the DataFrame\n",
    "def get_embedding(command):\n",
    "    encoded_input = tokenizer(command, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    # Perform mean pooling\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    \n",
    "    # Return the sentence embedding (flattened to 1D tensor)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the embedding function to each row in the DataFrame\n",
    "df_balanced[\"Embeddings\"] = df_balanced[\"Command\"].apply(lambda x: get_embedding(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#Storing df with embeddings in a pickle file\n",
    "with open('df_embeddings.pickle','wb') as file:\n",
    "    pickle.dump(df_balanced,file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('df_embeddings.pickle', 'rb') as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_balanced.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.MAX_MEM_USAGE_MB.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_balanced['MAX_MEM_USAGE_MB'] > 10000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(df):\n",
    "    # getting the first embedding element\n",
    "    df[\"emb_0\"] = df[\"Embeddings\"].apply(lambda x: x[0][0].item())\n",
    "    print(df[\"emb_0\"])\n",
    "    print(df[\"MAX_MEM_USAGE_MB\"])\n",
    "    #scatter plot for the first embedding and memory\n",
    "    plt.scatter(df[\"emb_0\"], df[\"MAX_MEM_USAGE_MB\"], alpha=0.5)\n",
    "    plt.xlabel(f\"First Embedding dimension\")\n",
    "    plt.ylabel(\"Memory\")\n",
    "    plt.title(\"Scatter plot of first embedding dimension vs Memory\")\n",
    "    plt.show()\n",
    "testing(df_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def testing(df):\n",
    "    # getting the first embedding element\n",
    "    df[\"emb_0\"] = df[\"Embeddings\"].apply(lambda x: x[0][0].item())\n",
    "    print(df[\"emb_0\"])\n",
    "    #print(df[\"MAX_MEM_USAGE_MB\"])\n",
    "    X = df[[\"emb_0\"]].values  \n",
    "    # Transform the target variable using natural log plus one\n",
    "    y = np.log1p(df[\"MAX_MEM_USAGE_MB\"].values)\n",
    "    \n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Step 4: Predict on training data\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Step 5: Plot prediction vs actual\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(y_pred, y, alpha=0.3, c='royalblue', label='Predicted', marker='o')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Predicted Memory Used from emb_0\")\n",
    "    plt.ylabel(\"Actual memory used\")\n",
    "    plt.title(\"Predicted vs Actual (using emb_0 only)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Done testing(). Model coefficient:\", model.coef_, \"Intercept:\", model.intercept_)\n",
    "testing(df_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensors in the Embeddings column to lists\n",
    "df[\"Embeddings\"] = df[\"Embeddings\"].apply(lambda x: [tensor.tolist() for tensor in x])\n",
    "\n",
    "# Save to new JSON file\n",
    "df.to_json(\"/Users/dn10/Downloads/Bsub_dataset/data_with_embeddings.jsonl.gz\", orient='records', lines=True, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame with embeddings\n",
    "#Cleaning the data\n",
    "df = pd.read_json(\"/Users/dn10/Downloads/Bsub_dataset/data_with_embeddings.jsonl.gz\", lines=True, compression='gzip')\n",
    "#df[\"MAX_MEM_USAGE_MB\"] = pd.to_numeric(df[\"MAX_MEM_USAGE_MB\"], errors = \"coerce\") # Convert to numeric, set errors to coerce to replace invalid parsing with NaN\n",
    "#df = df[df[\"MAX_MEM_USAGE_MB\"].notnull()].reset_index(drop=True)\n",
    "#df[\"NUM_EXEC_PROCS\"] = pd.to_numeric(df[\"NUM_EXEC_PROCS\"], errors = \"coerce\")\n",
    "#df = df[df[\"NUM_EXEC_PROCS\"].notnull()].reset_index(drop=True)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Pytorch Dataset class for the embeddings\n",
    "\n",
    "class CommandDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            df(pd.DataFrame): DataFrame containing entire dataset with embeddings\n",
    "        \"\"\"\n",
    "        self.commands = df[\"Command\"]\n",
    "        '''\n",
    "\n",
    "        For efficiency, we convert the columns with numbers to tensors of float32 type.\n",
    "\n",
    "        '''\n",
    "        self.memory_requested = torch.tensor(df[\"MEM_REQUESTED_MB\"].values, dtype=torch.float32)\n",
    "        self.memory_used = torch.tensor(df[\"MAX_MEM_USAGE_MB\"].values, dtype=torch.float32)\n",
    "        self.num_of_processors = torch.tensor(df[\"NUM_EXEC_PROCS\"].values,dtype=torch.float32)\n",
    "        '''\n",
    "\n",
    "        Assuming we have tensor of embeddings\n",
    "\n",
    "        ''' \n",
    "        #print(df[\"Embeddings\"][0])\n",
    "        self.embeddings = df[\"Embeddings\"]\n",
    "        \n",
    "\n",
    "\n",
    "        print(f\"Initialized CommandDataset with {len(self)}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''\n",
    "\n",
    "        Returns the length in the dataset/ number of commands\n",
    "\n",
    "        '''\n",
    "        return len(self.commands)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "\n",
    "        Returns the item at the given index\n",
    "\n",
    "        Args:\n",
    "            idx(int): index of the item to return\n",
    "        Returns:\n",
    "            dict: Dictionary containing the command, memory requested, memory used, number of processors, and embeddings\n",
    "\n",
    "        '''\n",
    "        commands = self.commands.iloc[idx]\n",
    "        memory_requested = self.memory_requested[idx]\n",
    "        memory_used = self.memory_used[idx]\n",
    "        num_of_processors = self.num_of_processors[idx]\n",
    "        embeddings = self.embeddings[idx]\n",
    "\n",
    "        data = {\n",
    "            \"command\": commands,\n",
    "            \"memory_requested\": memory_requested,\n",
    "            \"memory_used\": memory_used,\n",
    "            \"num_of_processors\": num_of_processors,\n",
    "            \"embeddings\": embeddings\n",
    "        }\n",
    "\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"MAX_MEM_USAGE_MB\"])\n",
    "print(df.columns)\n",
    "print(df['MAX_MEM_USAGE_MB'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CommandDataset(df_balanced)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_with_labels(dataset, test_size=0.2):\n",
    "    # Calculate the number of samples for train and test\n",
    "    train_size = int(len(dataset) * (1 - test_size))\n",
    "    test_size = len(dataset) - train_size\n",
    "    \n",
    "    # Perform the random split\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "    print(f\"Dataset split into {len(train_dataset)} training samples and {len(test_dataset)} testing samples\")\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = split_dataset_with_labels(data, test_size=0.2)\n",
    "\n",
    "# Print the object types to verify\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the training set\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "# Create a DataLoader for the testing set\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a scikit-learn model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# extract the embeddings and memory used from the training set\n",
    "X_train = torch.cat([batch[\"embeddings\"] for batch in train_loader]).squeeze(1)\n",
    "print(X_train.shape)\n",
    "Y_train = torch.cat([batch[\"memory_used\"] for batch in train_loader])\n",
    "print(Y_train.shape)\n",
    "\n",
    "#train the model\n",
    "sk_model = LinearRegression()\n",
    "sk_model.fit(X_train.numpy(), Y_train.numpy())  # Convert tensors to numpy arrays\n",
    "\n",
    "#get weights and bias\n",
    "sk_weights = sk_model.coef_\n",
    "sk_bias = sk_model.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on the training set\n",
    "Y_pred = sk_model.predict(X_train.numpy())\n",
    "print(Y_pred[:10])\n",
    "print(Y_train[:10])\n",
    "# Calculate the Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_train = mean_squared_error(Y_train.numpy(), Y_pred)\n",
    "print(f\"Training MSE: {mse_train}\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(Y_train, Y_pred, alpha=0.6, color='teal', edgecolor='k')\n",
    "plt.xlabel(\"Actual Memory Used\")\n",
    "plt.ylabel(\"Predicted Memory Used\")\n",
    "plt.title(\"Sklearn Linear Regression: Predictions vs Actual on Training Set\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(Y_train.mean())\n",
    "\n",
    "print(Y_pred.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batches = [batch[\"embeddings\"] for batch in train_loader]\n",
    "print(all_batches[0].shape)  # Access the shape of the first tensor directly\n",
    "\n",
    "batches = torch.cat(all_batches).squeeze(1)  # Squeeze the second dimension after concatenation\n",
    "print(batches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    embedding_size = data[i][\"embeddings\"].size(1)\n",
    "    print(f\"Embedding size for row {i}: {embedding_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Linear Regression Model\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim,output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pred_y = self.linear(x)\n",
    "        return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model\n",
    "input_dim = data[0][\"embeddings\"].size(1)\n",
    "output_dim = 1\n",
    "model = LinearRegression(input_dim,output_dim)\n",
    "\n",
    "#Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Define the optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign weights and bias to the model\n",
    "model.linear.weight.data = torch.tensor(sk_weights, dtype=torch.float32).unsqueeze(0)\n",
    "model.linear.bias.data = torch.tensor(sk_bias, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "model.train()\n",
    "losses = []\n",
    "for epoch in range(50):\n",
    "    for batch in train_loader:\n",
    "        #Forward pass\n",
    "        # Reshape embeddings to ensure they are 2D\n",
    "        pred_y = model(batch[\"embeddings\"])\n",
    "\n",
    "        #Loss calculation\n",
    "        loss = criterion(pred_y, batch[\"memory_used\"])\n",
    "        #append the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        #Backward pass\n",
    "        #Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update the weights\n",
    "        optimizer.step()\n",
    "        print (f\" Epoch { epoch} Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "input_dim = data[0][\"embeddings\"].size(1) # Size of the embeddings # getting the number of input features \n",
    "output_dim = 1 # asking for a single output value (memory used)\n",
    "model = LinearRegression(input_dim, output_dim) # model is an instance of the LinearRegression class with the input and output dimensions\n",
    "#Instantiate the loss function\n",
    "criterion = nn.MSELoss()  # Mean Squared Error \n",
    "\n",
    "#Instantiate the optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()   # Set the model to training mode\n",
    "loss_list = []  # store all the calculated loss values\n",
    "for epoch in range(500):   # 500 epochs\n",
    "    for batch in train_loader:   \n",
    "\n",
    "        #print(batch.keys())\n",
    "        # Forward pass: Compute predicted y by passing \n",
    "        # x to the model\n",
    "        pred_y = model(batch[\"embeddings\"])      #calls the forward method of the model(an instance of the LinearRegression class)\n",
    "    \n",
    "        # Compute  loss\n",
    "        loss = criterion(pred_y, batch[\"memory_used\"])  # criterion is an instance of the MSELoss class\n",
    "        # storing the calculated loss in a list\n",
    "        loss_list.append(loss.item())\n",
    "    \n",
    "        # Zero gradients, perform a backward pass, \n",
    "        # and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.linear.weight.grad)  # View gradients before zeroing\n",
    "optimizer.zero_grad()\n",
    "print(model.linear.weight.grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the weights and bias\n",
    "weights = model.linear.weight.data\n",
    "bias = model.linear.bias.data\n",
    "print(f\"Weights: {weights}\")\n",
    "print(f\"Bias: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"After step - {name}: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), '/Users/dn10/Downloads/Bsub_dataset/model.pth') # pytorch function like pickle which saves an object to a file\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "# Load the saved model\n",
    "model.load_state_dict(torch.load('/Users/dn10/Downloads/Bsub_dataset/model.pth'))\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = nn.MSELoss()  \n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss = 0\n",
    "total_predictions = numpy.array([])\n",
    "total_actual = numpy.array([])\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for batch in test_loader:\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        pred_y = model(batch[\"embeddings\"])\n",
    "\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(pred_y, batch[\"memory_used\"])\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        test_loss += loss.item()\n",
    "        pred_y = pred_y.squeeze()\n",
    "        print(f\"Predicted: {pred_y}, Actual: {batch['memory_used']}\")\n",
    "        print(pred_y.shape)\n",
    "        print(batch['memory_used'].shape)\n",
    "        total_predictions = numpy.append(total_predictions, pred_y.numpy())\n",
    "        total_actual = numpy.append(total_actual,batch['memory_used'].numpy())\n",
    "# Average test loss\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(total_predictions)\n",
    "print(total_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot a scatter plot for total prediction and total actual\n",
    "plt.scatter(total_predictions, total_actual, alpha=0.5, s= 20)\n",
    "plt.xlabel('Predicted memory used')\n",
    "plt.ylabel('Actual memory used')\n",
    "plt.title('Predictions vs Actual')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
